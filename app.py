import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score, max_error
import plotly.express as px
import plotly.graph_objects as go
import time
from sklearn.preprocessing import StandardScaler

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="æœºå™¨å­¦ä¹ å›å½’åˆ†æå·¥å…·", layout="wide")
st.title("æœºå™¨å­¦ä¹ å›å½’åˆ†æå·¥å…·")

# æ·»åŠ æ•°æ®æ ¼å¼æç¤º
st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ•°æ®æ–‡ä»¶ä¸­æ‰€æœ‰éœ€è¦ç”¨äºåˆ†æçš„åˆ—éƒ½æ˜¯æ•°å­—æ ¼å¼ã€‚")
st.markdown("""
**æ•°æ®è¦æ±‚ï¼š**
- æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼šCSVã€Excel (xls/xlsx)
- æ‰€æœ‰ç”¨äºåˆ†æçš„åˆ—å¿…é¡»æ˜¯æ•°å­—æ ¼å¼
- å¦‚æœå­˜åœ¨éæ•°å­—æ ¼å¼çš„åˆ—ï¼Œå°†åœ¨æ•°æ®é¢„è§ˆæ—¶æç¤º
""")

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader("è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶", type=['csv', 'xlsx', 'xls'])

if uploaded_file is not None:
    # è¯»å–æ•°æ®
    try:
        if uploaded_file.name.endswith('csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
        st.write("æ•°æ®é¢„è§ˆï¼š")
        st.dataframe(df.head())
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns
        
        if len(non_numeric_columns) > 0:
            st.warning("âš ï¸ æ£€æµ‹åˆ°ä»¥ä¸‹åˆ—åŒ…å«éæ•°å­—æ ¼å¼æ•°æ®ï¼Œè¿™äº›åˆ—ä¸èƒ½ç”¨äºå›å½’åˆ†æï¼š")
            for col in non_numeric_columns:
                st.write(f"- {col} (æ•°æ®ç±»å‹: {df[col].dtype})")
            st.write("è¯·åªé€‰æ‹©æ•°å­—æ ¼å¼çš„åˆ—ä½œä¸ºç‰¹å¾å˜é‡å’Œç›®æ ‡å˜é‡ã€‚")
        
        # åœ¨ç‰¹å¾é€‰æ‹©ä¹‹å‰æ·»åŠ 
        # æ•°æ®é¢„å¤„ç†é€‰é¡¹
        st.subheader("æ•°æ®é¢„å¤„ç†")

        # å¤„ç†ç¼ºå¤±å€¼é€‰é¡¹
        handle_missing = st.checkbox("å¤„ç†ç¼ºå¤±å€¼")
        if handle_missing:
            # åªå¤„ç†æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼
            numeric_df = df[numeric_columns]
            missing_method = st.radio(
                "é€‰æ‹©ç¼ºå¤±å€¼å¤„ç†æ–¹æ³•ï¼š",
                [
                    "å‡å€¼å¡«å……ï¼ˆç”¨è¯¥åˆ—çš„å¹³å‡å€¼å¡«å……ï¼‰",
                    "ä¸­ä½æ•°å¡«å……ï¼ˆç”¨è¯¥åˆ—çš„ä¸­ä½æ•°å¡«å……ï¼‰",
                    "ä¼—æ•°å¡«å……ï¼ˆç”¨è¯¥åˆ—çš„æœ€å¸¸è§å€¼å¡«å……ï¼‰",
                    "åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ",
                ]
            )
            
        # æ•°æ®æ ‡å‡†åŒ–é€‰é¡¹
        normalize_data = st.checkbox("æ•°æ®æ ‡å‡†åŒ–")
        if normalize_data:
            normalize_method = st.radio(
                "é€‰æ‹©æ ‡å‡†åŒ–æ–¹æ³•ï¼š",
                [
                    "æ ‡å‡†åŒ–(StandardScaler: å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1)",
                    "æœ€å°æœ€å¤§ç¼©æ”¾(MinMaxScaler: ç¼©æ”¾åˆ°0-1ä¹‹é—´)",
                    "ç¨³å¥ç¼©æ”¾(RobustScaler: å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ)",
                    "æ­£è§„åŒ–(Normalizer: å°†æ ·æœ¬ç¼©æ”¾åˆ°å•ä½èŒƒæ•°)"
                ]
            )
            
            # æ˜¾ç¤ºå°†è¦è¢«æ ‡å‡†åŒ–çš„åˆ—
            st.write("ä»¥ä¸‹æ•°å€¼åˆ—å°†è¢«æ ‡å‡†åŒ–ï¼š")
            st.write(list(numeric_columns))
            
        # æ·»åŠ ç¡®è®¤æŒ‰é’®
        if st.button("ç¡®è®¤æ•°æ®é¢„å¤„ç†"):
            # å¤„ç†ç¼ºå¤±å€¼
            if handle_missing:
                if missing_method == "å‡å€¼å¡«å……ï¼ˆç”¨è¯¥åˆ—çš„å¹³å‡å€¼å¡«å……ï¼‰":
                    df[numeric_columns] = numeric_df.fillna(numeric_df.mean())
                    st.success("âœ… å·²ä½¿ç”¨å‡å€¼å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼")
                elif missing_method == "ä¸­ä½æ•°å¡«å……ï¼ˆç”¨è¯¥åˆ—çš„ä¸­ä½æ•°å¡«å……ï¼‰":
                    df[numeric_columns] = numeric_df.fillna(numeric_df.median())
                    st.success("âœ… å·²ä½¿ç”¨ä¸­ä½æ•°å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼")
                elif missing_method == "ä¼—æ•°å¡«å……ï¼ˆç”¨è¯¥åˆ—çš„æœ€å¸¸è§å€¼å¡«å……ï¼‰":
                    df[numeric_columns] = numeric_df.fillna(numeric_df.mode().iloc[0])
                    st.success("âœ… å·²ä½¿ç”¨ä¼—æ•°å¡«å……æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼")
                else:  # åˆ é™¤å«ç¼ºå¤±å€¼çš„è¡Œ
                    # åªè€ƒè™‘æ•°å€¼åˆ—çš„ç¼ºå¤±å€¼
                    rows_with_missing = numeric_df.isnull().any(axis=1)
                    original_rows = len(df)
                    df = df[~rows_with_missing]
                    removed_rows = original_rows - len(df)
                    st.success(f"âœ… å·²åˆ é™¤æ•°å€¼åˆ—åŒ…å«ç¼ºå¤±å€¼çš„è¡Œï¼Œå…±åˆ é™¤äº† {removed_rows} è¡Œæ•°æ®")

            # æ•°æ®æ ‡å‡†åŒ–
            if normalize_data:
                if normalize_method == "æ ‡å‡†åŒ–(StandardScaler: å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1)":
                    scaler = StandardScaler()
                    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])
                    st.success("âœ… å·²ä½¿ç”¨StandardScalerå®Œæˆæ ‡å‡†åŒ–")
                    
                elif normalize_method == "æœ€å°æœ€å¤§ç¼©æ”¾(MinMaxScaler: ç¼©æ”¾åˆ°0-1ä¹‹é—´)":
                    from sklearn.preprocessing import MinMaxScaler
                    scaler = MinMaxScaler()
                    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])
                    st.success("âœ… å·²ä½¿ç”¨MinMaxScalerå®Œæˆå½’ä¸€åŒ–")
                    
                elif normalize_method == "ç¨³å¥ç¼©æ”¾(RobustScaler: å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ)":
                    from sklearn.preprocessing import RobustScaler
                    scaler = RobustScaler()
                    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])
                    st.success("âœ… å·²ä½¿ç”¨RobustScalerå®Œæˆç¨³å¥ç¼©æ”¾")
                    
                else:  # Normalizer
                    from sklearn.preprocessing import Normalizer
                    scaler = Normalizer()
                    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])
                    st.success("âœ… å·²ä½¿ç”¨Normalizerå®Œæˆæ­£è§„åŒ–")

            # æ˜¾ç¤ºé¢„å¤„ç†åçš„æ•°æ®é¢„è§ˆ
            st.write("æ•°æ®é¢„å¤„ç†åçš„é¢„è§ˆï¼š")
            st.dataframe(df[numeric_columns].head())

            # æ·»åŠ æ ‡å‡†åŒ–æ–¹æ³•è¯´æ˜
            if normalize_data:
                with st.expander("æŸ¥çœ‹æ ‡å‡†åŒ–æ–¹æ³•è¯´æ˜"):
                    st.markdown("""
                    **æ ‡å‡†åŒ–æ–¹æ³•è¯´æ˜ï¼š**
                    1. **æ ‡å‡†åŒ–(StandardScaler)**
                       - å°†æ•°æ®è½¬æ¢ä¸ºå‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1çš„åˆ†å¸ƒ
                       - é€‚ç”¨äºæ•°æ®å¤§è‡´å‘ˆæ­£æ€åˆ†å¸ƒçš„æƒ…å†µ
                       
                    2. **æœ€å°æœ€å¤§ç¼©æ”¾(MinMaxScaler)**
                       - å°†æ•°æ®ç¼©æ”¾åˆ°[0,1]åŒºé—´
                       - é€‚ç”¨äºæ•°æ®åˆ†å¸ƒæœ‰æ˜æ˜¾è¾¹ç•Œçš„æƒ…å†µ
                       
                    3. **ç¨³å¥ç¼©æ”¾(RobustScaler)**
                       - ä½¿ç”¨ç»Ÿè®¡é‡ï¼ˆä¸­ä½æ•°å’Œå››åˆ†ä½æ•°ï¼‰è¿›è¡Œç¼©æ”¾
                       - é€‚ç”¨äºæ•°æ®ä¸­å­˜åœ¨å¼‚å¸¸å€¼çš„æƒ…å†µ
                       
                    4. **æ­£è§„åŒ–(Normalizer)**
                       - å°†æ ·æœ¬ç¼©æ”¾åˆ°å•ä½èŒƒæ•°ï¼ˆæ¯ä¸ªæ ·æœ¬çš„èŒƒæ•°ä¸º1ï¼‰
                       - é€‚ç”¨äºéœ€è¦å¯¹æ ·æœ¬å‘é‡çš„æ–¹å‘æ›´æ•æ„Ÿçš„æƒ…å†µ
                    """)
        
        # é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡ï¼ˆåªæ˜¾ç¤ºæ•°å­—æ ¼å¼çš„åˆ—ï¼‰
        features = st.multiselect("é€‰æ‹©ç‰¹å¾å˜é‡ï¼ˆXï¼‰", numeric_columns)
        target = st.selectbox("é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆyï¼‰", numeric_columns)
        
        if features and target:
            X = df[features]
            y = df[target]
            
            # é€‰æ‹©æœºå™¨å­¦ä¹ æ–¹æ³•
            ml_methods = {
                "çº¿æ€§å›å½’": LinearRegression,
                "å²­å›å½’": Ridge,
                "Lassoå›å½’": Lasso,
                "æ”¯æŒå‘é‡å›å½’(SVR)": SVR,
                "éšæœºæ£®æ—å›å½’": RandomForestRegressor
            }
            
            selected_method = st.selectbox("é€‰æ‹©æœºå™¨å­¦ä¹ æ–¹æ³•", list(ml_methods.keys()))
            
            # æ ¹æ®é€‰æ‹©çš„æ–¹æ³•æ˜¾ç¤ºå‚æ•°è®¾ç½®
            params = {}
            if selected_method == "å²­å›å½’":
                alpha = st.number_input("alphaï¼ˆæ­£åˆ™åŒ–å¼ºåº¦ï¼Œå»ºè®®å€¼ï¼š0.1-10ï¼‰", 0.1, 100.0, 1.0)
                params['alpha'] = alpha
                
            elif selected_method == "Lassoå›å½’":
                alpha = st.number_input("alphaï¼ˆæ­£åˆ™åŒ–å¼ºåº¦ï¼Œå»ºè®®å€¼ï¼š0.1-10ï¼‰", 0.1, 100.0, 1.0)
                params['alpha'] = alpha
                
            elif selected_method == "æ”¯æŒå‘é‡å›å½’(SVR)":
                C = st.number_input("Cï¼ˆæ­£åˆ™åŒ–å‚æ•°ï¼Œå»ºè®®å€¼ï¼š1-10ï¼‰", 0.1, 100.0, 1.0)
                kernel = st.selectbox("æ ¸å‡½æ•°", ['rbf', 'linear', 'poly'])
                params['C'] = C
                params['kernel'] = kernel
                
            elif selected_method == "éšæœºæ£®æ—å›å½’":
                n_estimators = st.number_input("n_estimatorsï¼ˆæ ‘çš„æ•°é‡ï¼Œå»ºè®®å€¼ï¼š100ï¼‰", 10, 1000, 100)
                max_depth = st.number_input("max_depthï¼ˆæ ‘çš„æœ€å¤§æ·±åº¦ï¼Œå»ºè®®å€¼ï¼šNoneï¼‰", 1, 100, 10)
                params['n_estimators'] = n_estimators
                params['max_depth'] = max_depth
            
            # é€‰æ‹©ç»“æœå‘ˆç°æ–¹å¼
            st.subheader("é€‰æ‹©ç»“æœå‘ˆç°æ–¹å¼")
            show_metrics = st.checkbox("æ˜¾ç¤ºè¯„ä¼°æŒ‡æ ‡ï¼ˆRÂ², MSE, MAEï¼‰", value=True)
            show_scatter = st.checkbox("æ˜¾ç¤ºé¢„æµ‹å€¼vså®é™…å€¼æ•£ç‚¹å›¾", value=True)
            show_residuals = st.checkbox("æ˜¾ç¤ºæ®‹å·®å›¾", value=True)
            show_feature_importance = st.checkbox("æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§ï¼ˆé€‚ç”¨äºéšæœºæ£®æ—ï¼‰", value=True)
            
            # åœ¨æ¨¡å‹è®­ç»ƒä¹‹å‰æ·»åŠ 
            # äº¤å‰éªŒè¯è®¾ç½®
            cv_fold = st.number_input("äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆ0è¡¨ç¤ºä¸ä½¿ç”¨äº¤å‰éªŒè¯ï¼‰", 0, 10, 0)
            
            # åœ¨æ¨¡å‹å‚æ•°è®¾ç½®éƒ¨åˆ†æ·»åŠ 
            if st.checkbox("å¯ç”¨è¶…å‚æ•°ä¼˜åŒ–"):
                st.info("å°†ä½¿ç”¨ç½‘æ ¼æœç´¢å¯»æ‰¾æœ€ä¼˜å‚æ•°")
                
                if selected_method == "å²­å›å½’":
                    from sklearn.model_selection import GridSearchCV
                    param_grid = {
                        'alpha': [0.001, 0.01, 0.1, 1, 10, 100]
                    }
                    grid_search = GridSearchCV(Ridge(), param_grid, cv=5)
                    grid_search.fit(X_train, y_train)
                    model = grid_search.best_estimator_
                    st.success(f"æœ€ä¼˜å‚æ•°: {grid_search.best_params_}")
                    
                elif selected_method == "éšæœºæ£®æ—å›å½’":
                    param_grid = {
                        'n_estimators': [50, 100, 200],
                        'max_depth': [5, 10, 15, None]
                    }
                    grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5)
                    grid_search.fit(X_train, y_train)
                    model = grid_search.best_estimator_
                    st.success(f"æœ€ä¼˜å‚æ•°: {grid_search.best_params_}")
            
            # å¼€å§‹è¿è¡ŒæŒ‰é’®
            if st.button("å¼€å§‹è¿è¡Œ"):
                # åˆ†å‰²æ•°æ®
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
                
                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # è®­ç»ƒæ¨¡å‹
                model = ml_methods[selected_method](**params)
                
                # å¦‚æœéœ€è¦äº¤å‰éªŒè¯ï¼Œåœ¨æ¨¡å‹åˆ›å»ºåè¿›è¡Œ
                if cv_fold > 0:
                    from sklearn.model_selection import cross_val_score
                    cv_scores = cross_val_score(model, X, y, cv=cv_fold)
                    st.write(f"äº¤å‰éªŒè¯å¹³å‡å¾—åˆ†: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
                
                # æ›´æ–°è¿›åº¦
                for i in range(100):
                    progress_bar.progress(i + 1)
                    status_text.text(f"è®­ç»ƒè¿›åº¦ï¼š{i+1}%")
                    time.sleep(0.01)
                
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                
                # æ˜¾ç¤ºç»“æœ
                st.subheader("åˆ†æç»“æœ")
                
                # è¯„ä¼°æŒ‡æ ‡
                if show_metrics:
                    from sklearn.metrics import explained_variance_score, max_error
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("RÂ² å¾—åˆ†", f"{r2_score(y_test, y_pred):.3f}")
                        st.metric("è§£é‡Šæ–¹å·®åˆ†", f"{explained_variance_score(y_test, y_pred):.3f}")
                    with col2:
                        st.metric("å‡æ–¹è¯¯å·® (MSE)", f"{mean_squared_error(y_test, y_pred):.3f}")
                        st.metric("æœ€å¤§è¯¯å·®", f"{max_error(y_test, y_pred):.3f}")
                    with col3:
                        st.metric("å¹³å‡ç»å¯¹è¯¯å·® (MAE)", f"{mean_absolute_error(y_test, y_pred):.3f}")
                        st.metric("å‡æ–¹æ ¹è¯¯å·® (RMSE)", f"{np.sqrt(mean_squared_error(y_test, y_pred)):.3f}")
                
                # æ•£ç‚¹å›¾
                if show_scatter:
                    fig_scatter = px.scatter(
                        x=y_test, y=y_pred,
                        labels={'x': 'å®é™…å€¼', 'y': 'é¢„æµ‹å€¼'},
                        title='é¢„æµ‹å€¼ vs å®é™…å€¼'
                    )
                    fig_scatter.add_trace(
                        go.Scatter(x=[y_test.min(), y_test.max()], 
                                 y=[y_test.min(), y_test.max()],
                                 mode='lines', name='ç†æƒ³çº¿')
                    )
                    st.plotly_chart(fig_scatter)
                
                # æ®‹å·®å›¾
                if show_residuals:
                    residuals = y_test - y_pred
                    fig_residuals = px.scatter(
                        x=y_pred, y=residuals,
                        labels={'x': 'é¢„æµ‹å€¼', 'y': 'æ®‹å·®'},
                        title='æ®‹å·®å›¾'
                    )
                    st.plotly_chart(fig_residuals)
                
                # ç‰¹å¾é‡è¦æ€§
                if show_feature_importance and selected_method == "éšæœºæ£®æ—å›å½’":
                    importance = pd.DataFrame({
                        'feature': features,
                        'importance': model.feature_importances_
                    })
                    fig_importance = px.bar(
                        importance.sort_values('importance', ascending=True),
                        x='importance', y='feature',
                        title='ç‰¹å¾é‡è¦æ€§'
                    )
                    st.plotly_chart(fig_importance)
                
                st.success("åˆ†æå®Œæˆï¼")
                
                # åœ¨è®­ç»ƒå®Œæˆåæ·»åŠ 
                # æ¨¡å‹ä¿å­˜é€‰é¡¹
                if st.button("ä¿å­˜æ¨¡å‹"):
                    import pickle
                    with open('trained_model.pkl', 'wb') as f:
                        pickle.dump(model, f)
                    st.download_button(
                        label="ä¸‹è½½æ¨¡å‹æ–‡ä»¶",
                        data=open('trained_model.pkl', 'rb'),
                        file_name='trained_model.pkl',
                        mime='application/octet-stream'
                    )
                
                # åˆ›å»ºè¾“å‡ºç»“æœçš„å‡½æ•°
                def create_results_excel(model, X_train, X_test, y_train, y_test, y_pred, features, target, selected_method, params):
                    # åˆ›å»ºä¸€ä¸ª Excel writer å¯¹è±¡
                    output = pd.ExcelWriter('regression_results.xlsx', engine='xlsxwriter')
                    
                    # 1. æ¨¡å‹ä¿¡æ¯é¡µ
                    model_info = pd.DataFrame({
                        'é¡¹ç›®': ['ä½¿ç”¨çš„æ¨¡å‹', 'ç›®æ ‡å˜é‡', 'ç‰¹å¾å˜é‡', 'æ¨¡å‹å‚æ•°'],
                        'å€¼': [
                            selected_method,
                            target,
                            ', '.join(features),
                            str(params)
                        ]
                    })
                    model_info.to_excel(output, sheet_name='æ¨¡å‹ä¿¡æ¯', index=False)
                    
                    # 2. è¯„ä¼°æŒ‡æ ‡é¡µ
                    metrics = pd.DataFrame({
                        'è¯„ä¼°æŒ‡æ ‡': ['RÂ² å¾—åˆ†', 'å‡æ–¹è¯¯å·® (MSE)', 'å¹³å‡ç»å¯¹è¯¯å·® (MAE)'],
                        'å€¼': [
                            r2_score(y_test, y_pred),
                            mean_squared_error(y_test, y_pred),
                            mean_absolute_error(y_test, y_pred)
                        ]
                    })
                    metrics.to_excel(output, sheet_name='è¯„ä¼°æŒ‡æ ‡', index=False)
                    
                    # 3. é¢„æµ‹ç»“æœé¡µ
                    results_df = pd.DataFrame({
                        'å®é™…å€¼': y_test,
                        'é¢„æµ‹å€¼': y_pred,
                        'æ®‹å·®': y_test - y_pred
                    })
                    results_df.to_excel(output, sheet_name='é¢„æµ‹ç»“æœ', index=True)
                    
                    # 4. å¦‚æœæ˜¯éšæœºæ£®æ—ï¼Œæ·»åŠ ç‰¹å¾é‡è¦æ€§
                    if selected_method == "éšæœºæ£®æ—å›å½’":
                        importance = pd.DataFrame({
                            'ç‰¹å¾': features,
                            'é‡è¦æ€§': model.feature_importances_
                        })
                        importance = importance.sort_values('é‡è¦æ€§', ascending=False)
                        importance.to_excel(output, sheet_name='ç‰¹å¾é‡è¦æ€§', index=False)
                    
                    # ä¿å­˜æ–‡ä»¶
                    output.save()
                    
                    # è¯»å–æ–‡ä»¶å†…å®¹ç”¨äºä¸‹è½½
                    with open('regression_results.xlsx', 'rb') as f:
                        return f.read()

                # æ·»åŠ å¯¼å‡ºç»“æœæŒ‰é’®
                if st.button("å¯¼å‡ºåˆ†æç»“æœ"):
                    # åˆ›å»ºç»“æœæ–‡ä»¶
                    excel_data = create_results_excel(
                        model=model,
                        X_train=X_train,
                        X_test=X_test,
                        y_train=y_train,
                        y_test=y_test,
                        y_pred=y_pred,
                        features=features,
                        target=target,
                        selected_method=selected_method,
                        params=params
                    )
                    
                    # æä¾›ä¸‹è½½æŒ‰é’®
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½åˆ†æç»“æœ(Excel)",
                        data=excel_data,
                        file_name='regression_results.xlsx',
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                    )
                    
                    st.success("âœ… åˆ†æç»“æœå·²å‡†å¤‡å®Œæˆï¼Œè¯·ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®ä¸‹è½½ï¼")
                    
                    # æ˜¾ç¤ºç»“æœæ–‡ä»¶å†…å®¹é¢„è§ˆ
                    st.write("Excelæ–‡ä»¶åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š")
                    st.markdown("""
                    1. **æ¨¡å‹ä¿¡æ¯**
                       - ä½¿ç”¨çš„æ¨¡å‹ç±»å‹
                       - ç›®æ ‡å˜é‡
                       - ç‰¹å¾å˜é‡åˆ—è¡¨
                       - æ¨¡å‹å‚æ•°è®¾ç½®
                       
                    2. **è¯„ä¼°æŒ‡æ ‡**
                       - RÂ² å¾—åˆ†
                       - å‡æ–¹è¯¯å·® (MSE)
                       - å¹³å‡ç»å¯¹è¯¯å·® (MAE)
                       
                    3. **é¢„æµ‹ç»“æœ**
                       - æµ‹è¯•é›†å®é™…å€¼
                       - é¢„æµ‹å€¼
                       - æ®‹å·®
                       
                    4. **ç‰¹å¾é‡è¦æ€§** (ä»…éšæœºæ£®æ—æ¨¡å‹)
                       - å„ç‰¹å¾çš„é‡è¦æ€§å¾—åˆ†
                    """)
                
        # åœ¨æ•°æ®é¢„è§ˆåæ·»åŠ æ•°æ®æ¢ç´¢éƒ¨åˆ†
        if st.checkbox("æ•°æ®æ¢ç´¢ä¸å¯è§†åŒ–"):
            st.subheader("æ•°æ®æ¢ç´¢ä¸å¯è§†åŒ–")
            
            # åŸºç¡€ç»Ÿè®¡åˆ†æ
            if st.checkbox("æŸ¥çœ‹åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"):
                st.write("æ•°å€¼åˆ—ç»Ÿè®¡æè¿°ï¼š")
                st.write(df[numeric_columns].describe())
                
                # ç¼ºå¤±å€¼åˆ†æ
                missing_data = df[numeric_columns].isnull().sum()
                if missing_data.sum() > 0:
                    st.write("ç¼ºå¤±å€¼ç»Ÿè®¡ï¼š")
                    missing_df = pd.DataFrame({
                        'åˆ—å': missing_data.index,
                        'ç¼ºå¤±å€¼æ•°é‡': missing_data.values,
                        'ç¼ºå¤±å€¼æ¯”ä¾‹(%)': (missing_data.values / len(df) * 100).round(2)
                    })
                    st.write(missing_df)
            
            # æ•°æ®åˆ†å¸ƒå¯è§†åŒ–
            if st.checkbox("æ•°æ®åˆ†å¸ƒåˆ†æ"):
                col_for_dist = st.selectbox("é€‰æ‹©è¦åˆ†æçš„åˆ—ï¼š", numeric_columns)
                
                col1, col2 = st.columns(2)
                with col1:
                    # ç›´æ–¹å›¾
                    fig_hist = px.histogram(df, x=col_for_dist, 
                                          title=f"{col_for_dist}çš„åˆ†å¸ƒç›´æ–¹å›¾",
                                          marginal="box")  # æ·»åŠ ç®±çº¿å›¾
                    st.plotly_chart(fig_hist)
                    
                with col2:
                    # Q-Qå›¾
                    from scipy import stats
                    qq_data = stats.probplot(df[col_for_dist].dropna(), dist="norm")
                    fig_qq = px.scatter(x=qq_data[0][0], y=qq_data[0][1],
                                      title=f"{col_for_dist}çš„Q-Qå›¾")
                    fig_qq.add_trace(go.Scatter(x=qq_data[0][0], 
                                              y=qq_data[0][0] * qq_data[1][0] + qq_data[1][1],
                                              mode='lines', name='ç†è®ºåˆ†å¸ƒçº¿'))
                    st.plotly_chart(fig_qq)
            
            # ç›¸å…³æ€§åˆ†æ
            if st.checkbox("ç›¸å…³æ€§åˆ†æ"):
                corr_method = st.radio("é€‰æ‹©ç›¸å…³ç³»æ•°è®¡ç®—æ–¹æ³•ï¼š", 
                                     ["Pearson", "Spearman", "Kendall"])
                corr_matrix = df[numeric_columns].corr(method=corr_method.lower())
                
                # çƒ­åŠ›å›¾
                fig_heatmap = px.imshow(corr_matrix,
                                       title=f"{corr_method}ç›¸å…³ç³»æ•°çƒ­åŠ›å›¾",
                                       color_continuous_scale="RdBu",
                                       aspect="auto")
                st.plotly_chart(fig_heatmap)
                
                # æ˜¾ç¤ºå…·ä½“çš„ç›¸å…³ç³»æ•°
                if st.checkbox("æŸ¥çœ‹å…·ä½“ç›¸å…³ç³»æ•°"):
                    st.write(corr_matrix.round(3))
                    
                    # æ‰¾å‡ºé«˜ç›¸å…³çš„ç‰¹å¾å¯¹
                    threshold = st.slider("é€‰æ‹©ç›¸å…³ç³»æ•°é˜ˆå€¼", 0.0, 1.0, 0.8)
                    high_corr = np.where(np.abs(corr_matrix) > threshold)
                    high_corr_list = [(corr_matrix.index[x], corr_matrix.columns[y], 
                                      corr_matrix.iloc[x, y])
                                     for x, y in zip(*high_corr) if x != y]
                    
                    if high_corr_list:
                        st.write(f"ç›¸å…³ç³»æ•°ç»å¯¹å€¼å¤§äº{threshold}çš„ç‰¹å¾å¯¹ï¼š")
                        for feat1, feat2, corr in high_corr_list:
                            st.write(f"{feat1} - {feat2}: {corr:.3f}")
        
        # åœ¨æ•°æ®é¢„è§ˆåæ·»åŠ æ•°æ®æ¸…æ´—éƒ¨åˆ†
        if st.checkbox("æ•°æ®æ¸…æ´—"):
            st.subheader("æ•°æ®æ¸…æ´—")
            
            # å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†
            if st.checkbox("å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†"):
                method = st.radio(
                    "é€‰æ‹©å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•ï¼š",
                    ["IQRæ–¹æ³•", "Z-scoreæ–¹æ³•", "éš”ç¦»æ£®æ—"]
                )
                
                if method == "IQRæ–¹æ³•":
                    for col in numeric_columns:
                        Q1 = df[col].quantile(0.25)
                        Q3 = df[col].quantile(0.75)
                        IQR = Q3 - Q1
                        lower_bound = Q1 - 1.5 * IQR
                        upper_bound = Q3 + 1.5 * IQR
                        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]
                        if len(outliers) > 0:
                            st.write(f"{col} åˆ—ä¸­æ£€æµ‹åˆ° {len(outliers)} ä¸ªå¼‚å¸¸å€¼")
                            
                            handle_method = st.radio(
                                f"é€‰æ‹© {col} åˆ—å¼‚å¸¸å€¼å¤„ç†æ–¹æ³•ï¼š",
                                ["æ›¿æ¢ä¸ºè¾¹ç•Œå€¼", "åˆ é™¤å¼‚å¸¸å€¼è¡Œ", "ä¸å¤„ç†"],
                                key=f"outlier_{col}"
                            )
                            
                            if handle_method == "æ›¿æ¢ä¸ºè¾¹ç•Œå€¼":
                                df.loc[df[col] < lower_bound, col] = lower_bound
                                df.loc[df[col] > upper_bound, col] = upper_bound
                                st.success(f"{col} åˆ—å¼‚å¸¸å€¼å·²æ›¿æ¢ä¸ºè¾¹ç•Œå€¼")
                            elif handle_method == "åˆ é™¤å¼‚å¸¸å€¼è¡Œ":
                                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]
                                st.success(f"å·²åˆ é™¤ {col} åˆ—çš„å¼‚å¸¸å€¼è¡Œ")
        
        # åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåæ·»åŠ 
        if st.checkbox("é¢„æµ‹æ–°æ•°æ®"):
            st.subheader("æ–°æ•°æ®é¢„æµ‹")
            
            # æä¾›ä¸¤ç§è¾“å…¥æ–¹å¼
            input_method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["æ‰‹åŠ¨è¾“å…¥", "ä¸Šä¼ æ–‡ä»¶"])
            
            if input_method == "æ‰‹åŠ¨è¾“å…¥":
                new_data = {}
                for feature in features:
                    new_data[feature] = st.number_input(f"è¾“å…¥ {feature} çš„å€¼")
                
                if st.button("è¿›è¡Œé¢„æµ‹"):
                    new_df = pd.DataFrame([new_data])
                    prediction = model.predict(new_df)
                    st.success(f"é¢„æµ‹ç»“æœ: {prediction[0]:.4f}")
                    
            else:
                new_file = st.file_uploader("ä¸Šä¼ æ–°æ•°æ®æ–‡ä»¶", type=['csv', 'xlsx', 'xls'])
                if new_file is not None:
                    if new_file.name.endswith('csv'):
                        new_df = pd.read_csv(new_file)
                    else:
                        new_df = pd.read_excel(new_file)
                        
                    if all(feature in new_df.columns for feature in features):
                        predictions = model.predict(new_df[features])
                        new_df['é¢„æµ‹ç»“æœ'] = predictions
                        st.write("é¢„æµ‹ç»“æœï¼š")
                        st.write(new_df)
                        
                        # æä¾›ä¸‹è½½é¢„æµ‹ç»“æœ
                        output = pd.ExcelWriter('predictions.xlsx', engine='xlsxwriter')
                        new_df.to_excel(output, index=False)
                        output.save()
                        
                        with open('predictions.xlsx', 'rb') as f:
                            st.download_button(
                                label="ä¸‹è½½é¢„æµ‹ç»“æœ",
                                data=f,
                                file_name='predictions.xlsx',
                                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                            )
                    else:
                        st.error("æ–°æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„ç‰¹å¾åˆ—")
        
        # åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆåæ·»åŠ 
        if st.checkbox("æ¨¡å‹è§£é‡Š"):
            st.subheader("æ¨¡å‹è§£é‡Š")
            
            if selected_method in ["çº¿æ€§å›å½’", "å²­å›å½’", "Lassoå›å½’"]:
                # æ˜¾ç¤ºç‰¹å¾ç³»æ•°
                coef_df = pd.DataFrame({
                    'ç‰¹å¾': features,
                    'ç³»æ•°': model.coef_
                })
                st.write("ç‰¹å¾ç³»æ•°ï¼š")
                st.write(coef_df)
                
                # å¯è§†åŒ–ç‰¹å¾é‡è¦æ€§
                fig_coef = px.bar(coef_df, x='ç‰¹å¾', y='ç³»æ•°',
                                 title='ç‰¹å¾ç³»æ•°å¯è§†åŒ–')
                st.plotly_chart(fig_coef)
            
            # æ·»åŠ SHAPå€¼è§£é‡Š
            if st.checkbox("æ˜¾ç¤ºSHAPå€¼è§£é‡Š"):
                import shap
                explainer = shap.TreeExplainer(model) if selected_method == "éšæœºæ£®æ—å›å½’" \
                    else shap.LinearExplainer(model, X_train)
                shap_values = explainer.shap_values(X_test)
                
                st.write("SHAPå€¼æ‘˜è¦å›¾ï¼š")
                fig_shap = shap.summary_plot(shap_values, X_test, show=False)
                st.pyplot(fig_shap)
        
        # åœ¨æ•°æ®æ¸…æ´—åæ·»åŠ ç‰¹å¾å·¥ç¨‹éƒ¨åˆ†
        if st.checkbox("ç‰¹å¾å·¥ç¨‹"):
            st.subheader("ç‰¹å¾å·¥ç¨‹")
            
            # å¤šé¡¹å¼ç‰¹å¾
            if st.checkbox("æ·»åŠ å¤šé¡¹å¼ç‰¹å¾"):
                degree = st.slider("é€‰æ‹©å¤šé¡¹å¼åº¦æ•°", 2, 5, 2)
                from sklearn.preprocessing import PolynomialFeatures
                poly = PolynomialFeatures(degree=degree, include_bias=False)
                poly_features = poly.fit_transform(df[features])
                poly_feature_names = poly.get_feature_names_out(features)
                
                df_poly = pd.DataFrame(poly_features, columns=poly_feature_names)
                st.write("å¤šé¡¹å¼ç‰¹å¾é¢„è§ˆï¼š")
                st.write(df_poly.head())
                
                if st.button("ä½¿ç”¨å¤šé¡¹å¼ç‰¹å¾"):
                    features = list(poly_feature_names)
                    X = df_poly
                    st.success("å·²æ·»åŠ å¤šé¡¹å¼ç‰¹å¾")
            
            # ç‰¹å¾äº¤äº’
            if st.checkbox("æ·»åŠ ç‰¹å¾äº¤äº’é¡¹"):
                selected_features = st.multiselect(
                    "é€‰æ‹©è¦åˆ›å»ºäº¤äº’é¡¹çš„ç‰¹å¾ï¼ˆæœ€å¤šé€‰æ‹©2ä¸ªï¼‰ï¼š",
                    features,
                    max_selections=2
                )
                
                if len(selected_features) == 2:
                    interaction_name = f"{selected_features[0]}_{selected_features[1]}"
                    df[interaction_name] = df[selected_features[0]] * df[selected_features[1]]
                    features.append(interaction_name)
                    st.success(f"å·²æ·»åŠ ç‰¹å¾äº¤äº’é¡¹ï¼š{interaction_name}")
        
        # åœ¨æœºå™¨å­¦ä¹ æ–¹æ³•é€‰æ‹©éƒ¨åˆ†æ·»åŠ 
        if st.checkbox("ä½¿ç”¨æ¨¡å‹é›†æˆ"):
            st.subheader("æ¨¡å‹é›†æˆ")
            
            ensemble_method = st.radio(
                "é€‰æ‹©é›†æˆæ–¹æ³•ï¼š",
                ["æŠ•ç¥¨å›å½’", "å †å å›å½’"]
            )
            
            if ensemble_method == "æŠ•ç¥¨å›å½’":
                from sklearn.ensemble import VotingRegressor
                
                base_models = []
                if st.checkbox("ä½¿ç”¨çº¿æ€§å›å½’"):
                    base_models.append(('lr', LinearRegression()))
                if st.checkbox("ä½¿ç”¨å²­å›å½’"):
                    base_models.append(('ridge', Ridge()))
                if st.checkbox("ä½¿ç”¨éšæœºæ£®æ—"):
                    base_models.append(('rf', RandomForestRegressor()))
                    
                if len(base_models) >= 2:
                    model = VotingRegressor(base_models)
                    st.success("å·²åˆ›å»ºæŠ•ç¥¨å›å½’æ¨¡å‹")
                    
            elif ensemble_method == "å †å å›å½’":
                from sklearn.ensemble import StackingRegressor
                
                estimators = []
                if st.checkbox("ä½¿ç”¨çº¿æ€§å›å½’ä½œä¸ºåŸºæ¨¡å‹"):
                    estimators.append(('lr', LinearRegression()))
                if st.checkbox("ä½¿ç”¨å²­å›å½’ä½œä¸ºåŸºæ¨¡å‹"):
                    estimators.append(('ridge', Ridge()))
                if st.checkbox("ä½¿ç”¨éšæœºæ£®æ—ä½œä¸ºåŸºæ¨¡å‹"):
                    estimators.append(('rf', RandomForestRegressor()))
                    
                final_estimator = st.selectbox(
                    "é€‰æ‹©æœ€ç»ˆæ¨¡å‹ï¼š",
                    ["çº¿æ€§å›å½’", "å²­å›å½’", "éšæœºæ£®æ—"]
                )
                
                if len(estimators) >= 2:
                    if final_estimator == "çº¿æ€§å›å½’":
                        final = LinearRegression()
                    elif final_estimator == "å²­å›å½’":
                        final = Ridge()
                    else:
                        final = RandomForestRegressor()
                        
                    model = StackingRegressor(
                        estimators=estimators,
                        final_estimator=final,
                        cv=5
                    )
                    st.success("å·²åˆ›å»ºå †å å›å½’æ¨¡å‹")

        # åœ¨æ¨¡å‹è¯„ä¼°éƒ¨åˆ†æ·»åŠ 
        if st.checkbox("æ˜¾ç¤ºå­¦ä¹ æ›²çº¿"):
            from sklearn.model_selection import learning_curve
            
            train_sizes, train_scores, test_scores = learning_curve(
                model, X, y, cv=5, n_jobs=-1, 
                train_sizes=np.linspace(0.1, 1.0, 10)
            )
            
            train_mean = np.mean(train_scores, axis=1)
            train_std = np.std(train_scores, axis=1)
            test_mean = np.mean(test_scores, axis=1)
            test_std = np.std(test_scores, axis=1)
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=train_sizes, y=train_mean,
                name='è®­ç»ƒé›†å¾—åˆ†',
                mode='lines+markers'
            ))
            fig.add_trace(go.Scatter(
                x=train_sizes, y=test_mean,
                name='éªŒè¯é›†å¾—åˆ†',
                mode='lines+markers'
            ))
            fig.update_layout(
                title='å­¦ä¹ æ›²çº¿',
                xaxis_title='è®­ç»ƒæ ·æœ¬æ•°',
                yaxis_title='å¾—åˆ†'
            )
            st.plotly_chart(fig)

        # åœ¨ç‰¹å¾å·¥ç¨‹éƒ¨åˆ†æ·»åŠ 
        if st.checkbox("ç‰¹å¾é€‰æ‹©"):
            st.subheader("ç‰¹å¾é€‰æ‹©")
            
            selection_method = st.radio("é€‰æ‹©ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼š",
                                      ["æ–¹å·®é˜ˆå€¼æ³•", "äº’ä¿¡æ¯æ³•", "é€’å½’ç‰¹å¾æ¶ˆé™¤(RFE)", 
                                       "LASSOç‰¹å¾é€‰æ‹©"])
            
            if selection_method == "æ–¹å·®é˜ˆå€¼æ³•":
                from sklearn.feature_selection import VarianceThreshold
                threshold = st.slider("é€‰æ‹©æ–¹å·®é˜ˆå€¼", 0.0, 1.0, 0.0, 0.01)
                selector = VarianceThreshold(threshold=threshold)
                X_selected = selector.fit_transform(X)
                selected_features = X.columns[selector.get_support()].tolist()
                
            elif selection_method == "äº’ä¿¡æ¯æ³•":
                from sklearn.feature_selection import mutual_info_regression
                mi_scores = mutual_info_regression(X, y)
                mi_df = pd.DataFrame({'ç‰¹å¾': X.columns, 'äº’ä¿¡æ¯å¾—åˆ†': mi_scores})
                mi_df = mi_df.sort_values('äº’ä¿¡æ¯å¾—åˆ†', ascending=False)
                
                st.write("ç‰¹å¾äº’ä¿¡æ¯å¾—åˆ†ï¼š")
                st.write(mi_df)
                
                n_features = st.slider("é€‰æ‹©ä¿ç•™çš„ç‰¹å¾æ•°é‡", 1, len(features), len(features))
                selected_features = mi_df['ç‰¹å¾'].head(n_features).tolist()
                
            elif selection_method == "é€’å½’ç‰¹å¾æ¶ˆé™¤(RFE)":
                from sklearn.feature_selection import RFE
                n_features = st.slider("é€‰æ‹©ä¿ç•™çš„ç‰¹å¾æ•°é‡", 1, len(features), len(features))
                estimator = RandomForestRegressor(n_estimators=100, random_state=42)
                selector = RFE(estimator=estimator, n_features_to_select=n_features)
                selector.fit(X, y)
                selected_features = X.columns[selector.support_].tolist()
                
            else:  # LASSOç‰¹å¾é€‰æ‹©
                from sklearn.linear_model import LassoCV
                lasso = LassoCV(cv=5, random_state=42)
                lasso.fit(X, y)
                
                importance_df = pd.DataFrame({
                    'ç‰¹å¾': X.columns,
                    'ç³»æ•°': np.abs(lasso.coef_)
                }).sort_values('ç³»æ•°', ascending=False)
                
                st.write("LASSOç‰¹å¾é‡è¦æ€§ï¼š")
                st.write(importance_df)
                
                coef_threshold = st.slider("é€‰æ‹©ç³»æ•°é˜ˆå€¼", 0.0, 
                                         float(importance_df['ç³»æ•°'].max()), 0.01)
                selected_features = importance_df[importance_df['ç³»æ•°'] > coef_threshold]['ç‰¹å¾'].tolist()
            
            st.write("é€‰ä¸­çš„ç‰¹å¾ï¼š", selected_features)
            if st.button("ä½¿ç”¨é€‰ä¸­çš„ç‰¹å¾"):
                features = selected_features
                X = df[features]
                st.success(f"å·²æ›´æ–°ç‰¹å¾é›†ï¼Œå½“å‰ä½¿ç”¨{len(features)}ä¸ªç‰¹å¾")

        # åœ¨æ¨¡å‹è¯„ä¼°éƒ¨åˆ†æ·»åŠ 
        if st.checkbox("æ¨¡å‹è¯Šæ–­"):
            st.subheader("æ¨¡å‹è¯Šæ–­")
            
            # æ®‹å·®åˆ†æ
            residuals = y_test - y_pred
            
            # æ®‹å·®çš„æ­£æ€æ€§æ£€éªŒ
            from scipy import stats
            stat, p_value = stats.normaltest(residuals)
            st.write(f"æ®‹å·®æ­£æ€æ€§æ£€éªŒ p-value: {p_value:.4f}")
            if p_value < 0.05:
                st.warning("æ®‹å·®å¯èƒ½ä¸æœä»æ­£æ€åˆ†å¸ƒ")
            else:
                st.success("æ®‹å·®æœä»æ­£æ€åˆ†å¸ƒ")
            
            # æ®‹å·®çš„å„ç§å›¾
            col1, col2 = st.columns(2)
            with col1:
                # æ®‹å·®ç›´æ–¹å›¾
                fig_res_hist = px.histogram(residuals, 
                                          title="æ®‹å·®åˆ†å¸ƒç›´æ–¹å›¾",
                                          marginal="box")
                st.plotly_chart(fig_res_hist)
                
            with col2:
                # æ®‹å·®Q-Qå›¾
                qq_data = stats.probplot(residuals, dist="norm")
                fig_qq = px.scatter(x=qq_data[0][0], y=qq_data[0][1],
                                  title="æ®‹å·®Q-Qå›¾")
                fig_qq.add_trace(go.Scatter(x=qq_data[0][0], 
                                          y=qq_data[0][0] * qq_data[1][0] + qq_data[1][1],
                                          mode='lines', name='ç†è®ºåˆ†å¸ƒçº¿'))
                st.plotly_chart(fig_qq)

        # åœ¨é¢„æµ‹å®Œæˆåæ·»åŠ 
        if st.checkbox("é¢„æµ‹ç»“æœåˆ†æ"):
            st.subheader("é¢„æµ‹ç»“æœåˆ†æ")
            
            # é¢„æµ‹è¯¯å·®åˆ†å¸ƒ
            error_df = pd.DataFrame({
                'å®é™…å€¼': y_test,
                'é¢„æµ‹å€¼': y_pred,
                'ç»å¯¹è¯¯å·®': np.abs(y_test - y_pred),
                'ç›¸å¯¹è¯¯å·®(%)': (np.abs(y_test - y_pred) / y_test * 100)
            })
            
            st.write("é¢„æµ‹è¯¯å·®ç»Ÿè®¡ï¼š")
            st.write(error_df.describe())
            
            # è¯¯å·®åˆ†å¸ƒå›¾
            col1, col2 = st.columns(2)
            with col1:
                fig_error_hist = px.histogram(error_df, x='ç»å¯¹è¯¯å·®',
                                            title="ç»å¯¹è¯¯å·®åˆ†å¸ƒ")
                st.plotly_chart(fig_error_hist)
            
            with col2:
                fig_error_rel = px.histogram(error_df, x='ç›¸å¯¹è¯¯å·®(%)',
                                           title="ç›¸å¯¹è¯¯å·®åˆ†å¸ƒ")
                st.plotly_chart(fig_error_rel)
            
            # é¢„æµ‹å‡†ç¡®åº¦åˆ†æ
            error_threshold = st.slider("é€‰æ‹©å¯æ¥å—çš„ç›¸å¯¹è¯¯å·®é˜ˆå€¼(%)", 0, 100, 10)
            accurate_predictions = (error_df['ç›¸å¯¹è¯¯å·®(%)'] <= error_threshold).sum()
            accuracy = accurate_predictions / len(error_df) * 100
            
            st.metric(f"é¢„æµ‹å‡†ç¡®ç‡ (ç›¸å¯¹è¯¯å·®â‰¤{error_threshold}%)", 
                      f"{accuracy:.2f}%")

    except Exception as e:
        st.error(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}") 